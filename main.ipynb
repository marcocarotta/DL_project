{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the entry point for the project.\n",
    "The choice of .ipynb it's for speeding up the training using Google Colab or Kaggle machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters all to be set here\n",
    "block_size = 128 #sequence lenght\n",
    "embedding_dim = 512  # Embedding dimensions\n",
    "num_heads = 8  # Number of attention heads\n",
    "num_layers = 8  # Number of transformer blocks\n",
    "ff_hid_dim = 1024 # feed forward hidden dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading\n",
    "In the following code block we instanciate the dataset and use some method for analyse it and preprocess it.\n",
    "\n",
    "### Comments \n",
    "- as of now it's a little bit too verbose the analysis, consider adding a verbose parameter in the dataset_analysis method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:CharDataset:### Dataset Analysis ###\n",
      "INFO:CharDataset:### Comparison with Original Dataset ###\n",
      "INFO:CharDataset:Original Total Characters: 1115394\n",
      "INFO:CharDataset:Current Total Characters: 1115394\n",
      "INFO:CharDataset:Original Unique Characters: 65\n",
      "INFO:CharDataset:Current Unique Characters: 65\n",
      "INFO:CharDataset:### Detailed Current Dataset Analysis ###\n",
      "INFO:CharDataset:### Characters and Frequencies ###\n",
      "INFO:CharDataset:'␣': 169892\n",
      "INFO:CharDataset:'e': 94611\n",
      "INFO:CharDataset:'t': 67009\n",
      "INFO:CharDataset:'o': 65798\n",
      "INFO:CharDataset:'a': 55507\n",
      "INFO:CharDataset:'h': 51310\n",
      "INFO:CharDataset:'s': 49696\n",
      "INFO:CharDataset:'r': 48889\n",
      "INFO:CharDataset:'n': 48529\n",
      "INFO:CharDataset:'i': 45537\n",
      "INFO:CharDataset:'\\n': 40000\n",
      "INFO:CharDataset:'l': 33339\n",
      "INFO:CharDataset:'d': 31358\n",
      "INFO:CharDataset:'u': 26584\n",
      "INFO:CharDataset:'m': 22243\n",
      "INFO:CharDataset:'y': 20448\n",
      "INFO:CharDataset:',': 19846\n",
      "INFO:CharDataset:'w': 17585\n",
      "INFO:CharDataset:'f': 15770\n",
      "INFO:CharDataset:'c': 15623\n",
      "INFO:CharDataset:'g': 13356\n",
      "INFO:CharDataset:'I': 11832\n",
      "INFO:CharDataset:'b': 11321\n",
      "INFO:CharDataset:'p': 10808\n",
      "INFO:CharDataset:':': 10316\n",
      "INFO:CharDataset:'.': 7885\n",
      "INFO:CharDataset:'A': 7819\n",
      "INFO:CharDataset:'v': 7793\n",
      "INFO:CharDataset:'k': 7088\n",
      "INFO:CharDataset:'T': 7015\n",
      "INFO:CharDataset:''': 6187\n",
      "INFO:CharDataset:'E': 6041\n",
      "INFO:CharDataset:'O': 5481\n",
      "INFO:CharDataset:'N': 5079\n",
      "INFO:CharDataset:'R': 4869\n",
      "INFO:CharDataset:'S': 4523\n",
      "INFO:CharDataset:'L': 3876\n",
      "INFO:CharDataset:'C': 3820\n",
      "INFO:CharDataset:';': 3628\n",
      "INFO:CharDataset:'W': 3530\n",
      "INFO:CharDataset:'U': 3313\n",
      "INFO:CharDataset:'H': 3068\n",
      "INFO:CharDataset:'M': 2840\n",
      "INFO:CharDataset:'B': 2761\n",
      "INFO:CharDataset:'?': 2462\n",
      "INFO:CharDataset:'G': 2399\n",
      "INFO:CharDataset:'!': 2172\n",
      "INFO:CharDataset:'D': 2089\n",
      "INFO:CharDataset:'-': 1897\n",
      "INFO:CharDataset:'F': 1797\n",
      "INFO:CharDataset:'Y': 1718\n",
      "INFO:CharDataset:'P': 1641\n",
      "INFO:CharDataset:'K': 1584\n",
      "INFO:CharDataset:'V': 798\n",
      "INFO:CharDataset:'j': 628\n",
      "INFO:CharDataset:'q': 609\n",
      "INFO:CharDataset:'x': 529\n",
      "INFO:CharDataset:'z': 356\n",
      "INFO:CharDataset:'J': 320\n",
      "INFO:CharDataset:'Q': 231\n",
      "INFO:CharDataset:'Z': 198\n",
      "INFO:CharDataset:'X': 112\n",
      "INFO:CharDataset:'3': 27\n",
      "INFO:CharDataset:'&': 3\n",
      "INFO:CharDataset:'$': 1\n",
      "INFO:CharDataset:### Sequence Analysis ###\n",
      "INFO:CharDataset:Number of Lines: 40001\n",
      "INFO:CharDataset:Average Line Length (in char): 26.88\n",
      "INFO:CharDataset:Max Line Length (in char): 63\n",
      "INFO:CharDataset:### Character Set Changes ###\n",
      "INFO:CharDataset:No changes in character set.\n",
      "INFO:CharDataset:Removed characters with frequency < 10 and replaced them with '@' token.\n",
      "INFO:CharDataset:### Dataset Analysis ###\n",
      "INFO:CharDataset:### Comparison with Original Dataset ###\n",
      "INFO:CharDataset:Original Total Characters: 1115394\n",
      "INFO:CharDataset:Current Total Characters: 1115394\n",
      "INFO:CharDataset:Original Unique Characters: 65\n",
      "INFO:CharDataset:Current Unique Characters: 64\n",
      "INFO:CharDataset:### Detailed Current Dataset Analysis ###\n",
      "INFO:CharDataset:### Characters and Frequencies ###\n",
      "INFO:CharDataset:'␣': 169892\n",
      "INFO:CharDataset:'e': 94611\n",
      "INFO:CharDataset:'t': 67009\n",
      "INFO:CharDataset:'o': 65798\n",
      "INFO:CharDataset:'a': 55507\n",
      "INFO:CharDataset:'h': 51310\n",
      "INFO:CharDataset:'s': 49696\n",
      "INFO:CharDataset:'r': 48889\n",
      "INFO:CharDataset:'n': 48529\n",
      "INFO:CharDataset:'i': 45537\n",
      "INFO:CharDataset:'\\n': 40000\n",
      "INFO:CharDataset:'l': 33339\n",
      "INFO:CharDataset:'d': 31358\n",
      "INFO:CharDataset:'u': 26584\n",
      "INFO:CharDataset:'m': 22243\n",
      "INFO:CharDataset:'y': 20448\n",
      "INFO:CharDataset:',': 19846\n",
      "INFO:CharDataset:'w': 17585\n",
      "INFO:CharDataset:'f': 15770\n",
      "INFO:CharDataset:'c': 15623\n",
      "INFO:CharDataset:'g': 13356\n",
      "INFO:CharDataset:'I': 11832\n",
      "INFO:CharDataset:'b': 11321\n",
      "INFO:CharDataset:'p': 10808\n",
      "INFO:CharDataset:':': 10316\n",
      "INFO:CharDataset:'.': 7885\n",
      "INFO:CharDataset:'A': 7819\n",
      "INFO:CharDataset:'v': 7793\n",
      "INFO:CharDataset:'k': 7088\n",
      "INFO:CharDataset:'T': 7015\n",
      "INFO:CharDataset:''': 6187\n",
      "INFO:CharDataset:'E': 6041\n",
      "INFO:CharDataset:'O': 5481\n",
      "INFO:CharDataset:'N': 5079\n",
      "INFO:CharDataset:'R': 4869\n",
      "INFO:CharDataset:'S': 4523\n",
      "INFO:CharDataset:'L': 3876\n",
      "INFO:CharDataset:'C': 3820\n",
      "INFO:CharDataset:';': 3628\n",
      "INFO:CharDataset:'W': 3530\n",
      "INFO:CharDataset:'U': 3313\n",
      "INFO:CharDataset:'H': 3068\n",
      "INFO:CharDataset:'M': 2840\n",
      "INFO:CharDataset:'B': 2761\n",
      "INFO:CharDataset:'?': 2462\n",
      "INFO:CharDataset:'G': 2399\n",
      "INFO:CharDataset:'!': 2172\n",
      "INFO:CharDataset:'D': 2089\n",
      "INFO:CharDataset:'-': 1897\n",
      "INFO:CharDataset:'F': 1797\n",
      "INFO:CharDataset:'Y': 1718\n",
      "INFO:CharDataset:'P': 1641\n",
      "INFO:CharDataset:'K': 1584\n",
      "INFO:CharDataset:'V': 798\n",
      "INFO:CharDataset:'j': 628\n",
      "INFO:CharDataset:'q': 609\n",
      "INFO:CharDataset:'x': 529\n",
      "INFO:CharDataset:'z': 356\n",
      "INFO:CharDataset:'J': 320\n",
      "INFO:CharDataset:'Q': 231\n",
      "INFO:CharDataset:'Z': 198\n",
      "INFO:CharDataset:'X': 112\n",
      "INFO:CharDataset:'3': 27\n",
      "INFO:CharDataset:'@': 4\n",
      "INFO:CharDataset:### Sequence Analysis ###\n",
      "INFO:CharDataset:Number of Lines: 40001\n",
      "INFO:CharDataset:Average Line Length (in char): 26.88\n",
      "INFO:CharDataset:Max Line Length (in char): 63\n",
      "INFO:CharDataset:### Character Set Changes ###\n",
      "INFO:CharDataset:Characters Removed: {'$', '&'}\n",
      "INFO:CharDataset:New Characters Added: {'@'}\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "import torch\n",
    "from dataset import CharDataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "try: \n",
    "    with open('dataset/dataset.txt', 'r') as file:\n",
    "        text = file.read()\n",
    "except FileNotFoundError:\n",
    "    with open('data/dataset.txt', 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "# Create dataset\n",
    "dataset = CharDataset(text, block_size)\n",
    "\n",
    "# Analyze original dataset\n",
    "dataset.dataset_analysis()\n",
    "\n",
    "# Remove less frequent characters and analyze the dataset\n",
    "dataset.remove_less_frequent_chars(10).dataset_analysis()\n",
    "\n",
    "dataset.preprocess()\n",
    "\n",
    "if 'train_dataset' in globals():\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
    "else:\n",
    "    loader = DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "\n",
    "### make this work in the future, as of now just use the whole dataset for training\n",
    "# # Split the dataset into training and validation sets\n",
    "# percentage = 0.9\n",
    "# split_point = int(len(dataset) * percentage)\n",
    "\n",
    "# # Slice the text for training and validation\n",
    "# train_text = text[:split_point]\n",
    "# val_text = text[split_point:]\n",
    "\n",
    "# # doing stupid split for now\n",
    "# train_dataset = CharDataset(train_text, block_size)\n",
    "# val_dataset = CharDataset(val_text, block_size)\n",
    "\n",
    "# # Instantiate DataLoader objects\n",
    "# train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciate the model\n",
    "Here we set the least amount of parameter needed for the model and call the model summary method\n",
    "\n",
    "### comments\n",
    "- as of now the model summary doesn't work (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:CharTransformer:Model initialized\n",
      "INFO:CharTransformer:### Model summary###\n",
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "CharTransformerSummaryWrapper                      [32, 128, 39]             --\n",
      "├─CharTransformer: 1-1                             [32, 128, 39]             65,536\n",
      "│    └─Embedding: 2-1                              [32, 128, 512]            19,968\n",
      "│    └─Dropout: 2-2                                [32, 128, 512]            --\n",
      "│    └─ModuleList: 2-3                             --                        --\n",
      "│    │    └─TransformerBlock: 3-1                  [32, 128, 512]            2,102,784\n",
      "│    │    └─TransformerBlock: 3-2                  [32, 128, 512]            2,102,784\n",
      "│    │    └─TransformerBlock: 3-3                  [32, 128, 512]            2,102,784\n",
      "│    │    └─TransformerBlock: 3-4                  [32, 128, 512]            2,102,784\n",
      "│    │    └─TransformerBlock: 3-5                  [32, 128, 512]            2,102,784\n",
      "│    │    └─TransformerBlock: 3-6                  [32, 128, 512]            2,102,784\n",
      "│    │    └─TransformerBlock: 3-7                  [32, 128, 512]            2,102,784\n",
      "│    │    └─TransformerBlock: 3-8                  [32, 128, 512]            2,102,784\n",
      "│    └─LayerNorm: 2-4                              [32, 128, 512]            1,024\n",
      "│    └─Linear: 2-5                                 [32, 128, 39]             20,007\n",
      "====================================================================================================\n",
      "Total params: 16,928,807\n",
      "Trainable params: 16,928,807\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 539.62\n",
      "====================================================================================================\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 1242.79\n",
      "Params size (MB): 67.45\n",
      "Estimated Total Size (MB): 1310.28\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from model import CharTransformer\n",
    "\n",
    "# usually should be train_dataset, but for now just use the whole dataset for training\n",
    "if 'train_dataset' in globals():\n",
    "    vocabulary_size = train_dataset.vocabulary_size\n",
    "else:\n",
    "    vocabulary_size = dataset.vocabulary_size\n",
    "\n",
    "# Initialize the model\n",
    "model = CharTransformer(vocabulary_size, block_size, embedding_dim, num_heads, num_layers, ff_hid_dim=ff_hid_dim)\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Trainer\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "# Set optimizer and loss function   \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(model, optimizer, loss_fn, loader)\n",
    "\n",
    "# Load model\n",
    "# trainer.load_model(\"models/second_run_medium/model_checkpoint_9_kaggle.pth\")\n",
    "\n",
    "# Train the model\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/validation/model_checkpoint_9_prelayernorm.pth\n"
     ]
    }
   ],
   "source": [
    "from generate import TextGenerator\n",
    "\n",
    "generator = TextGenerator(model, dataset)\n",
    "\n",
    "generator.load_model(\"models/validation/model_checkpoint_9_prelayernorm.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 0.20000000298023224\n",
      "\n",
      "\n",
      "clown:\n",
      "indeed, if it be too much blood, your pratest, as it were, farewell.\n",
      "\n",
      "archidamus:\n",
      "i think so. kill'd!\n",
      "she i kill'd! i did so: but thou strikest me\n",
      "sorely, to say i did; it is a power to die.\n",
      "\n",
      "nurse:\n",
      "hie to your gaoler, then, if you should say \n",
      "\n",
      "Temperature: 0.4000000059604645\n",
      "\n",
      "that i must be content: it is now to seem the ladies,\n",
      "i heard yet say the fortune and thee from?\n",
      "o, but the end the fire of thy foul sin!\n",
      "thou wilt not slaughter to me commend thee.\n",
      "\n",
      "first murderer:\n",
      "why, then he will say we stabbed him stand henry.\n",
      "\n",
      " \n",
      "\n",
      "Temperature: 0.6000000238418579\n",
      "\n",
      "that i must be contented. for this last,\n",
      "i tender hear from the garland of my soul,\n",
      "my fortune and this land will forget your command.\n",
      "\n",
      "lady grey:\n",
      "why, then i will give you good den  blood,\n",
      "and you but make, my maidenhead!\n",
      "\n",
      "nurse:\n",
      "how! waay! why come \n",
      "\n",
      "Temperature: 0.800000011920929\n",
      "\n",
      "brutus:\n",
      "ay, but wherefore dost thou regin thy face?\n",
      "ttell the pedlars he was the before the war\n",
      "that calls and romeo hath heard the news;\n",
      "or women was foul this, pleasure is, pity,\n",
      "that, i'll stay a little more for this once?\n",
      "what horse maid    fhim? \n",
      "\n",
      "Temperature: 1.0\n",
      "\n",
      "bear thy mother's blood this day should choose\n",
      "the citizens of choice; she cannot live,\n",
      "i doubt but rinnocency be will still.\n",
      "\n",
      "cominius:\n",
      "you have made good work!\n",
      "\n",
      "menenius:\n",
      "what ever this?\n",
      "\n",
      "cominius:\n",
      "yes, marcius.\n",
      "\n",
      "cominius:\n",
      "should this,ffeather?\n",
      "\n",
      "co \n",
      "\n",
      "Temperature: 1.2000000476837158\n",
      "\n",
      "lord of elbow:\n",
      "shall i follow ihmtogslnnew.\n",
      "\n",
      "hastings:\n",
      "indeed, if thy news?\n",
      "\n",
      "messenger:\n",
      "ah, oormman, beymeyood this gtae,\n",
      "rroee i mean to crave, to wash the brat?\n",
      "the bonas may rrmain as mine honesty:\n",
      "the one will outttto hee another be deliver'd.\n",
      "\n",
      "m \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "for temperature in torch.arange(0.2, 1.4, 0.2):\n",
    "    \n",
    "    generated_text = generator.generate(\"\\n\",length = 250, temperature=temperature)\n",
    "    print(f\"Temperature: {temperature}\")\n",
    "    print(generated_text,\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
